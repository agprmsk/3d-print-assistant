"""–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
import json
from pathlib import Path

try:
    from .config import RAW_DATA_DIR, PROCESSED_DATA_PATH
except ImportError:
    from src.config import RAW_DATA_DIR, PROCESSED_DATA_PATH


def normalize():
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –µ–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–∞ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞ —Ñ–∞–π–ª–æ–≤
    json_path = RAW_DATA_DIR / "3dtoday_articles.json"
    jsonl_path = RAW_DATA_DIR / "3dtoday_raw.jsonl"
    
    in_path = None
    if json_path.exists():
        in_path = json_path
        print(f"üìÑ –ù–∞–π–¥–µ–Ω JSON —Ñ–∞–π–ª: {json_path}")
    elif jsonl_path.exists():
        in_path = jsonl_path
        print(f"üìÑ –ù–∞–π–¥–µ–Ω JSONL —Ñ–∞–π–ª: {jsonl_path}")
    else:
        print(f"‚ö†Ô∏è –§–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω—ã:")
        print(f"   - {json_path}")
        print(f"   - {jsonl_path}")
        print("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python -m src.scraper_3dtoday")
        return
    
    processed_count = 0
    
    try:
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç
        with open(in_path, 'r', encoding='utf-8') as f:
            content = f.read().strip()
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ –º–∞—Å—Å–∏–≤ JSON
        try:
            data = json.loads(content)
            if isinstance(data, list):
                items = data
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω JSON –º–∞—Å—Å–∏–≤ ({len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤)")
            else:
                items = [data]
        except json.JSONDecodeError:
            # –ï—Å–ª–∏ –Ω–µ –º–∞—Å—Å–∏–≤, –ø—Ä–æ–±—É–µ–º –∫–∞–∫ JSONL (–ø–æ—Å—Ç—Ä–æ—á–Ω–æ)
            items = []
            for line in content.split('\n'):
                if line.strip():
                    items.append(json.loads(line))
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω JSONL ({len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤)")
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        with open(PROCESSED_DATA_PATH, 'w', encoding='utf-8') as fout:
            for item in items:
                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                doc = {
                    "id": item.get("url", f"doc_{processed_count}"),
                    "title": item.get("title", "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"),
                    "content": item.get("content", ""),
                    "source_url": item.get("url", ""),
                    "category": item.get("category", ""),
                    "tags": item.get("tags", []),
                }
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
                if not doc["content"] or len(doc["content"]) < 100:
                    continue
                
                fout.write(json.dumps(doc, ensure_ascii=False) + "\n")
                processed_count += 1
        
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        print(f"üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {PROCESSED_DATA_PATH}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    print("üîÑ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n")
    normalize()
